{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Official Objective: Create a python script that crawls specified news websites for articles matching given keywords, categorizes them by defined topics\n",
    "#Unofficial Objective: to eliminate my daily habit of doomscorlling the news :D\n",
    "\n",
    "#Assumptions: the results will all be relevant and the keywords selection is sufficient to capture the desired articles\n",
    "#Constraints: must handle errors gracefully, avoid duplicate articles, and respect website crawling policies (robots\n",
    "\n",
    "#first we import everything we may need\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the news web crawler as a class with functions\n",
    "\n",
    "class NewsCrawler:\n",
    "    def __init__(self, urls, keywords):\n",
    "        \"\"\"\n",
    "        Initialize the news crawler.\n",
    "        Args:\n",
    "            urls: List of news site URLs to crawl\n",
    "            keywords: Dictionary mapping topic names to lists of keywords\n",
    "                     e.g., {'Technology': ['AI', 'tech', 'software'], 'Politics': ['election', 'senate']}\n",
    "        \"\"\"\n",
    "        self.urls = urls\n",
    "        self.keywords = keywords\n",
    "        self.articles_by_topic = defaultdict(list)\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "    \n",
    "    def fetch_page(self, url):\n",
    "        \"\"\"Fetch a webpage and return its content.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")  #show the error message.  Some sites may require login\n",
    "            return None\n",
    "    \n",
    "    def extract_articles(self, html, base_url):\n",
    "        \"\"\"Extract article titles and links from HTML.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        articles = []\n",
    "        \n",
    "        # Look for common article elements\n",
    "        article_tags = soup.find_all(['article', 'div', 'li'], class_=re.compile(r'(article|story|post|item|card)'))\n",
    "        \n",
    "        for tag in article_tags:\n",
    "            # Try to find headline and link\n",
    "            link_tag = tag.find('a', href=True)\n",
    "            if not link_tag:\n",
    "                continue\n",
    "            \n",
    "            # Get title from various possible locations\n",
    "            title = None\n",
    "            title_tag = tag.find(['h1', 'h2', 'h3', 'h4'])\n",
    "            if title_tag:\n",
    "                title = title_tag.get_text(strip=True)\n",
    "            elif link_tag.get_text(strip=True):\n",
    "                title = link_tag.get_text(strip=True)\n",
    "            \n",
    "            if title and len(title) > 10:  # Filter out very short titles\n",
    "                url = urljoin(base_url, link_tag['href'])\n",
    "                articles.append({'title': title, 'url': url})\n",
    "        \n",
    "        # Also search for standard headline links if no articles found\n",
    "        if not articles:\n",
    "            for tag in soup.find_all('a', href=True):\n",
    "                text = tag.get_text(strip=True)\n",
    "                if len(text) > 20 and len(text) < 200:  # Reasonable title length\n",
    "                    url = urljoin(base_url, tag['href'])\n",
    "                    if '/article/' in url or '/news/' in url or '/story/' in url:\n",
    "                        articles.append({'title': text, 'url': url})\n",
    "        \n",
    "        return articles\n",
    "    \n",
    "    def categorize_article(self, article_text):\n",
    "        \"\"\"Determine which topic(s) an article belongs to based on keywords.\"\"\"\n",
    "        topics = []\n",
    "        article_lower = article_text.lower()\n",
    "        \n",
    "        for topic, keywords in self.keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword.lower() in article_lower:\n",
    "                    topics.append(topic)\n",
    "                    break  # Move to next topic once we find a match\n",
    "        \n",
    "        return topics\n",
    "    \n",
    "    def crawl(self):\n",
    "        \"\"\"Crawl all news sites and categorize articles.\"\"\"\n",
    "        print(\"Starting news crawl...\\n\")\n",
    "        \n",
    "        for url in self.urls:\n",
    "            print(f\"Crawling {url}...\")\n",
    "            html = self.fetch_page(url)\n",
    "            \n",
    "            if not html:\n",
    "                continue\n",
    "            \n",
    "            articles = self.extract_articles(html, url)\n",
    "            print(f\"Found {len(articles)} articles\")\n",
    "            \n",
    "            for article in articles:\n",
    "                topics = self.categorize_article(article['title'])\n",
    "                for topic in topics:\n",
    "                    self.articles_by_topic[topic].append(article)\n",
    "            \n",
    "            #add delay between requests\n",
    "            time.sleep(1)\n",
    "        \n",
    "        print(\"\\nCrawl complete!\\n\")\n",
    "    \n",
    "    def generate_summary(self):\n",
    "        \"\"\"Generate a bulleted summary of news by topic.\"\"\"\n",
    "        summary = []\n",
    "        summary.append(\"=\" * 60)\n",
    "        summary.append(\"NEWS SUMMARY BY TOPIC\")\n",
    "        summary.append(\"=\" * 60)\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        if not self.articles_by_topic:\n",
    "            summary.append(\"No articles found matching the specified topics.\")\n",
    "            return \"\\n\".join(summary)\n",
    "        \n",
    "        for topic in sorted(self.articles_by_topic.keys()):\n",
    "            articles = self.articles_by_topic[topic]\n",
    "            #Remove duplicates based on title by creating a dictionary of unique articles\n",
    "            unique_articles = {a['title']: a for a in articles}.values()\n",
    "            \n",
    "            summary.append(f\"\\n{topic.upper()}\")\n",
    "            summary.append(\"-\" * 60)\n",
    "            \n",
    "            for article in list(unique_articles)[:10]:  #Limit to 10 per topic\n",
    "                summary.append(f\"  • {article['title']}\")\n",
    "                summary.append(f\"    {article['url']}\")\n",
    "            \n",
    "            summary.append(f\"\\n  Total articles: {len(unique_articles)}\")\n",
    "            summary.append(\"\")\n",
    "        \n",
    "        return \"\\n\".join(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca1e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of news site URLs to crawl\n",
    "    \n",
    "news_urls = [\n",
    "    \"https://www.wsj.com\",                     # Wall Street Journal\n",
    "    \"https://news.ycombinator.com\",            # Y Combinator News (Hacker News)\n",
    "    \"https://techcrunch.com\",                  # TechCrunch\n",
    "    \"https://www.wired.com\",                   # Wired\n",
    "    \"https://www.economist.com\",               # The Economist\n",
    "    \"https://www.mddionline.com\",              # MD+DI (Medical Device and Diagnostic Industry)\n",
    "    \"https://www.bbc.com/news\",                # BBC News\n",
    "    \"https://www.nytimes.com\",                 # New York Times\n",
    "    \"https://www.ocregister.com\"               # Orange County Register\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Define topics and their associated keywords\n",
    "topics_keywords = {\n",
    "        \"Technology\": [\"AI\", \"artificial intelligence\", \"tech\", \"software\", \"computer\", \"digital\"],\n",
    "        \"Politics\": [\"election\", \"president\", \"senate\", \"congress\", \"政治\", \"政府\"],\n",
    "        \"Business\": [\"economy\", \"market\", \"stock\", \"company\", \"business\", \"financial\"],\n",
    "        \"Science\": [\"research\", \"study\", \"science\", \"discovery\", \"climate\"],\n",
    "        \"Health\": [\"health\", \"medical\", \"vaccine\", \"disease\", \"hospital\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6331b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting news crawl...\n",
      "\n",
      "Crawling https://www.wsj.com...\n",
      "Error fetching https://www.wsj.com: 401 Client Error: HTTP Forbidden for url: https://www.wsj.com/\n",
      "Crawling https://news.ycombinator.com...\n",
      "Found 2 articles\n",
      "Crawling https://techcrunch.com...\n",
      "Found 366 articles\n",
      "Crawling https://www.wired.com...\n",
      "Found 134 articles\n",
      "Crawling https://www.economist.com...\n",
      "Error fetching https://www.economist.com: 403 Client Error: Forbidden for url: https://www.economist.com/\n",
      "Crawling https://www.mddionline.com...\n",
      "Error fetching https://www.mddionline.com: 403 Client Error: Forbidden for url: https://www.mddionline.com/\n",
      "Crawling https://www.bbc.com/news...\n",
      "Found 39 articles\n",
      "Crawling https://www.nytimes.com...\n",
      "Found 29 articles\n",
      "Crawling https://www.ocregister.com...\n",
      "Found 220 articles\n",
      "\n",
      "Crawl complete!\n",
      "\n",
      "============================================================\n",
      "NEWS SUMMARY BY TOPIC\n",
      "============================================================\n",
      "\n",
      "\n",
      "BUSINESS\n",
      "------------------------------------------------------------\n",
      "  • Coinbase CEO Brian Armstrong trolls the prediction markets\n",
      "    https://techcrunch.com/2025/11/01/coinbase-ceo-brian-armstrong-trolls-the-prediction-markets/\n",
      "  • IntrCity SmartBus lands $30M at $140M valuation to deepen its grip on India’s intercity travel market\n",
      "    https://techcrunch.com/category/transportation/\n",
      "  • The WIRED Guide to Chicago for Business Travelers\n",
      "    https://www.wired.com/story/the-wired-guide-to-chicago-for-business-travelers/\n",
      "  • “I Sweated So Much I Never Needed to Pee”: Life in China’s Relentless Gig Economy\n",
      "    https://www.wired.com/story/made-in-china-i-deliver-parcels-in-beijing-author-interview/\n",
      "  • How Peter Thiel's Secretive Data Company Pushed Into Policing\n",
      "    https://www.wired.com/story/how-peter-thiels-secretive-data-company-pushed-into-policing/\n",
      "  • 'No idea who he is,' says Trump after pardoning crypto tycoonThe president pardoned Changpeng Zhao, the co-founder of the world's largest crypto exchange, in October.12 hrs agoBusiness\n",
      "    https://www.bbc.com/news/articles/cn7ek63e5xyo\n",
      "  • Kimberly-Clark to buy Tylenol-maker for more than $40bnThe deal will unite two giants in the over-the-counter health business, bringing together brands like Kleenex and Benadryl.3 hrs agoBusiness\n",
      "    https://www.bbc.com/news/articles/cr43dp99k4vo\n",
      "  • This Company Plans to Make Big Profits From Cuts to Medicaid\n",
      "    https://www.nytimes.com/2025/11/03/health/medicaid-cuts-equifax-data.html\n",
      "  • Marketplace\n",
      "    https://www.socalnewsgroup.com/advertising-solutions/marketplace/\n",
      "  • Get in Touch with a Marketing Strategist\n",
      "    https://www.socalnewsgroup.com/contact-us/\n",
      "\n",
      "  Total articles: 12\n",
      "\n",
      "\n",
      "HEALTH\n",
      "------------------------------------------------------------\n",
      "  • Are We Healthy Yet?\n",
      "    https://www.wired.com/beyond-wellness/\n",
      "  • Why brushing teeth twice a day is not always bestAccording to dental experts, even the most diligent brushers might be making a few mistakes.18 hrs agoHealth\n",
      "    https://www.bbc.com/news/articles/c803gk1vpzko\n",
      "  • Kimberly-Clark to buy Tylenol-maker for more than $40bnThe deal will unite two giants in the over-the-counter health business, bringing together brands like Kleenex and Benadryl.3 hrs agoBusiness\n",
      "    https://www.bbc.com/news/articles/cr43dp99k4vo\n",
      "  • Senate report details dozens of cases of medical neglect in federal immigration detention centers\n",
      "    https://www.ocregister.com/2025/10/31/immigration-detention-senate-probe/\n",
      "\n",
      "  Total articles: 4\n",
      "\n",
      "\n",
      "POLITICS\n",
      "------------------------------------------------------------\n",
      "  • Donald Trump Is the First AI Slop President\n",
      "    https://www.wired.com/story/donald-trump-ai-slop-white-house/\n",
      "  • 'No idea who he is,' says Trump after pardoning crypto tycoonThe president pardoned Changpeng Zhao, the co-founder of the world's largest crypto exchange, in October.12 hrs agoBusiness\n",
      "    https://www.bbc.com/news/articles/cn7ek63e5xyo\n",
      "  • Supreme Court Confronts Trump and His Tariffs in Test of Presidential Power\n",
      "    https://www.nytimes.com/2025/11/03/us/politics/supreme-court-trump-tariffs.html\n",
      "  • Ford Foundation’s New Leader Vows to Protect Elections and the Rule of Law\n",
      "    https://www.nytimes.com/2025/11/03/us/politics/ford-foundation-heather-gerken-trump.html\n",
      "  • Elections on Tuesday Offer Democrats a Chance to Get Off the Mat\n",
      "    https://www.nytimes.com/2025/11/03/us/politics/us-elections-democrats-trump.html\n",
      "  • Our Election Guide\n",
      "    https://www.nytimes.com/2025/11/03/briefing/our-election-guide.html\n",
      "  • N.Y.C. Mayoral Candidates Make Final Push Before Election Day\n",
      "    https://www.nytimes.com/live/2025/11/03/nyregion/nyc-mayor-election-news\n",
      "  • The president has no ‘foreign policy’ discretion to impose sweeping global tariffs\n",
      "    https://www.ocregister.com/2025/11/03/the-president-has-no-foreign-policy-discretion-to-impose-sweeping-global-tariffs/\n",
      "  • Newsom dabbles in honesty about his presidential ambitions\n",
      "    https://www.ocregister.com/2025/11/03/newsom-dabbles-in-honesty-about-his-presidential-ambitions/\n",
      "  • Senate report details dozens of cases of medical neglect in federal immigration detention centers\n",
      "    https://www.ocregister.com/2025/10/31/immigration-detention-senate-probe/\n",
      "\n",
      "  Total articles: 10\n",
      "\n",
      "\n",
      "SCIENCE\n",
      "------------------------------------------------------------\n",
      "  • AI researchers ’embodied’ an LLM into a robot – and it started channeling Robin Williams\n",
      "    https://techcrunch.com/2025/11/01/ai-researchers-embodied-an-llm-into-a-robot-and-it-started-channeling-robin-williams/\n",
      "  • Mississippi mum fatally shoots escaped research monkey\n",
      "    https://www.bbc.com/news/articles/cev18k70zkyo\n",
      "  • 10Mississippi mum fatally shoots escaped research monkey\n",
      "    https://www.bbc.com/news/articles/cev18k70zkyo\n",
      "\n",
      "  Total articles: 3\n",
      "\n",
      "\n",
      "TECHNOLOGY\n",
      "------------------------------------------------------------\n",
      "  • First recording of a dying human brain shows waves similar to memory flashbacks\n",
      "    https://louisville.edu/medicine/news/first-ever-recording-of-a-dying-human-brain-shows-waves-similar-to-memory-flashbacks\n",
      "  • Microsoft’s $15.2B UAE investment turns Gulf State into test case for US AI diplomacy\n",
      "    https://techcrunch.com/category/artificial-intelligence/\n",
      "  • Meta has an AI product problem\n",
      "    https://techcrunch.com/2025/11/02/meta-has-an-ai-product-problem/\n",
      "  • Kevin Rose’s simple test for AI hardware — would you want to punch someone in the face who’s wearing it?\n",
      "    https://techcrunch.com/category/artificial-intelligence/\n",
      "  • Sam Altman says ‘enough’ to questions about OpenAI’s revenue\n",
      "    https://techcrunch.com/category/artificial-intelligence/\n",
      "  • Google pulls Gemma from AI Studio after Senator Blackburn accuses model of defamation\n",
      "    https://techcrunch.com/2025/11/02/google-pulls-gemma-from-ai-studio-after-senator-blackburn-accuses-model-of-defamation/\n",
      "  • AI researchers ’embodied’ an LLM into a robot – and it started channeling Robin Williams\n",
      "    https://techcrunch.com/2025/11/01/ai-researchers-embodied-an-llm-into-a-robot-and-it-started-channeling-robin-williams/\n",
      "  • Aisha Malik\n",
      "    https://techcrunch.com/author/aisha-malik/\n",
      "  • Dia’s AI browser starts adding Arc’s ‘greatest hits’ to its feature set\n",
      "    https://techcrunch.com/category/apps/\n",
      "  • Pine Labs aims to take Indian fintech global even as it cuts valuation for IPO\n",
      "    https://techcrunch.com/category/fintech/\n",
      "\n",
      "  Total articles: 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create crawler and run\n",
    "    crawler = NewsCrawler(news_urls, topics_keywords)\n",
    "    crawler.crawl()\n",
    "    \n",
    "    # Print summary\n",
    "    print(crawler.generate_summary())\n",
    "    \n",
    "    # Optionally save to file\n",
    "    with open(\"news_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(crawler.generate_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
